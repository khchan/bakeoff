{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from semantic_kernel.agents import AssistantAgentThread, ResponsesAgentThread, AzureAssistantAgent, AzureResponsesAgent\n",
    "from azure.identity import EnvironmentCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "pool_management_endpoint = os.getenv(\"POOL_MANAGEMENT_ENDPOINT\")\n",
    "ai_project_endpoint = os.getenv(\"AI_PROJECT_ENDPOINT\")\n",
    "chat_endpoint=os.getenv(\"OPENAI_ENDPOINT\")\n",
    "model_deployment_name=os.getenv(\"OPENAI_DEPLOYMENT_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Kernel + AOAI Assistants API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Thread: ['assistant: The capital of France is Paris.', 'user: What is the capital of France?']\n",
      "# User: What about Canada?\n",
      "# Agent: The capital of Canada is Ottawa.\n"
     ]
    }
   ],
   "source": [
    "# 1. Create the client using Azure OpenAI resources and configuration\n",
    "provider = get_bearer_token_provider(EnvironmentCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "client = AzureAssistantAgent.create_client(\n",
    "    endpoint=chat_endpoint, \n",
    "    ad_token_provider=provider, \n",
    "    deployment_name=model_deployment_name,\n",
    "    api_version=\"2025-04-01-preview\"\n",
    ")\n",
    "\n",
    "# 2. Create the assistant on the Azure OpenAI service\n",
    "definition = await client.beta.assistants.create(\n",
    "    model=model_deployment_name,\n",
    "    name=\"ContextAssistant\",\n",
    "    instructions=\"Keep track of the context of the conversation and use it to answer the user's question.\",\n",
    ")\n",
    "\n",
    "# 3. Create a Semantic Kernel agent for the Azure OpenAI assistant\n",
    "agent = AzureAssistantAgent(client=client, definition=definition)\n",
    "\n",
    "# 4. Create a new thread for use with the assistant\n",
    "thread: AssistantAgentThread = AssistantAgentThread(client=client, messages=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the capital of France?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"The capital of France is Paris.\"\n",
    "    }\n",
    "])\n",
    "\n",
    "\n",
    "print(f\"# Thread: {[f'{msg.role}: {msg.content}' async for msg in thread.get_messages()]}\")\n",
    "TASK = \"What about Canada?\"\n",
    "print(f\"# User: {TASK}\")\n",
    "try:\n",
    "    # 5. Invoke the agent for the current thread and print the response\n",
    "    async for response in agent.invoke(messages=TASK, thread=thread):\n",
    "        print(f\"# Agent: {response}\")\n",
    "        thread = response.thread\n",
    "finally:\n",
    "    # 6. Clean up the resources\n",
    "    await thread.delete() if thread else None\n",
    "    await agent.client.beta.assistants.delete(agent.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Kernel + AOAI Responses API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: 'My name is John Doe.'\n",
      "# Joker: Nice to meet you, John Doe! How can I assist you today?\n",
      "# User: 'Tell me a joke'\n",
      "# Joker: Sure! Here's one for you:\n",
      "\n",
      "Why don't skeletons fight each other?  \n",
      "Because they don't have the guts! ðŸŽƒ\n",
      "# User: 'Explain why this is funny.'\n",
      "# Joker: Of course! Here's the breakdown:\n",
      "\n",
      "The humor in this joke comes from wordplay and a double meaning. When we say \"skeletons don't have the guts,\" the phrase serves as both a literal and figurative statement:\n",
      "\n",
      "1. **Literal Meaning**: Skeletons are just bonesâ€”they don't have organs like \"guts\" (intestines or internal organs). So, skeletons physically lack the \"guts\" to do anything.\n",
      "\n",
      "2. **Figurative Meaning**: The phrase \"don't have the guts\" is a common idiom that means lacking bravery or courage. By using this phrase in context with skeletons, the joke creates an amusing overlap between the literal and figurative interpretations.\n",
      "\n",
      "The humor comes from combining these two ideas in an unexpected way!\n",
      "# User: 'What have we been talking about?'\n",
      "# Joker: So far, we've had a friendly chat! Here's a summary:\n",
      "\n",
      "1. You introduced yourself as **John Doe**.\n",
      "2. I shared a joke about skeletons (\"Why don't skeletons fight each other? Because they don't have the guts!\").\n",
      "3. Then, you asked me to explain why the joke is funny, and I described the wordplay and double meaning behind it.\n",
      "\n",
      "That's the recapâ€”anything you'd like to add or explore further? ðŸ˜Š\n",
      "# User: 'What is my name?'\n",
      "# Joker: Your name is **John Doe**! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# 1. Create the client using Azure OpenAI resources and configuration\n",
    "provider = get_bearer_token_provider(EnvironmentCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "client = AzureResponsesAgent.create_client(\n",
    "    endpoint=chat_endpoint, \n",
    "    ad_token_provider=provider, \n",
    "    deployment_name=model_deployment_name,\n",
    "    api_version=\"2025-04-01-preview\"\n",
    ")\n",
    "\n",
    "# 2. Create a Semantic Kernel agent for the OpenAI Responses API\n",
    "agent = AzureResponsesAgent(\n",
    "    ai_model_id=model_deployment_name,\n",
    "    client=client,\n",
    "    instructions=\"Answer questions about from the user.\",\n",
    "    name=\"Joker\",\n",
    ")\n",
    "\n",
    "USER_INPUTS = [\n",
    "    \"My name is John Doe.\",\n",
    "    \"Tell me a joke\",\n",
    "    \"Explain why this is funny.\",\n",
    "    \"What have we been talking about?\",\n",
    "]\n",
    "\n",
    "# 3. Create a thread for the agent\n",
    "# If no thread is provided, a new thread will be\n",
    "# created and returned with the initial response\n",
    "thread = None\n",
    "\n",
    "for user_input in USER_INPUTS:\n",
    "    print(f\"# User: '{user_input}'\")\n",
    "    # 4. Invoke the agent for the current message and print the response\n",
    "    response = await agent.get_response(messages=user_input, thread=thread)\n",
    "    print(f\"# {response.name}: {response.content}\")\n",
    "    # 5. Update the thread so the previous response id is used\n",
    "    thread = response.thread\n",
    "\n",
    "# Continue with an existing thread id\n",
    "thread = ResponsesAgentThread(client=client, previous_response_id=thread.id)\n",
    "# 6. Ask the agent a new question to show the thread is still valid\n",
    "new_user_input = \"What is my name?\"\n",
    "print(f\"# User: '{new_user_input}'\")\n",
    "response = await agent.get_response(messages=new_user_input, thread=thread)\n",
    "print(f\"# {response.name}: {response.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
