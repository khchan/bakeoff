{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from semantic_kernel.agents import AssistantAgentThread, AzureAssistantAgent\n",
    "from azure.ai.agents.models import CodeInterpreterTool\n",
    "from semantic_kernel.agents import AzureAIAgent, AzureAIAgentThread\n",
    "from azure.identity import EnvironmentCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "pool_management_endpoint = os.getenv(\"POOL_MANAGEMENT_ENDPOINT\")\n",
    "ai_project_endpoint = os.getenv(\"AI_PROJECT_ENDPOINT\")\n",
    "chat_endpoint=os.getenv(\"OPENAI_ENDPOINT\")\n",
    "model_deployment_name=os.getenv(\"OPENAI_DEPLOYMENT_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Kernel + AOAI Assistants API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "Total succeeded: 100\n",
      "Total failed: 0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "from semantic_kernel.agents.open_ai.run_polling_options import RunPollingOptions\n",
    "\n",
    "# Custom polling strategy\n",
    "polling = RunPollingOptions(\n",
    "    run_polling_interval=timedelta(seconds=1),          # base wait between GET /runs\n",
    "    run_polling_backoff=timedelta(seconds=2),           # how much to add after N tries\n",
    "    run_polling_backoff_threshold=4,                    # after 4 polls, start backing off\n",
    "    maximum_retry_count=60                              # give up after 60 polls  (~90 s)\n",
    ")\n",
    "# 1. Create the client using Azure OpenAI resources and configuration\n",
    "provider = get_bearer_token_provider(EnvironmentCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "start_time = time.time()\n",
    "client = AzureAssistantAgent.create_client(\n",
    "    endpoint=chat_endpoint, \n",
    "    ad_token_provider=provider, \n",
    "    deployment_name=model_deployment_name,\n",
    "    api_version=\"2025-04-01-preview\"\n",
    ")\n",
    "\n",
    "# 2. Configure the code interpreter tool and resources for the Assistant\n",
    "code_interpreter_tool, code_interpreter_tool_resources = AzureAssistantAgent.configure_code_interpreter_tool()\n",
    "\n",
    "async def create_agent() -> bool:\n",
    "    # 3. Create the assistant on the Azure OpenAI service\n",
    "    definition = await client.beta.assistants.create(\n",
    "        model=model_deployment_name,\n",
    "        name=\"CodeRunner\",\n",
    "        instructions=\"Run the provided request as code and return the result. ALWAYS USE THE CODE INTERPRETER TOOL.\",\n",
    "        tools=code_interpreter_tool,\n",
    "        tool_resources=code_interpreter_tool_resources\n",
    "    )\n",
    "\n",
    "    # 4. Create a Semantic Kernel agent for the Azure OpenAI assistant\n",
    "    agent = AzureAssistantAgent(\n",
    "        client=client,\n",
    "        definition=definition,\n",
    "        polling=polling,\n",
    "    )\n",
    "\n",
    "    # 5. Create a new thread for use with the assistant\n",
    "    # If no thread is provided, a new thread will be\n",
    "    # created and returned with the initial response\n",
    "    thread: AssistantAgentThread = None\n",
    "\n",
    "    TASK = \"\"\"Use the python code interpreter, \n",
    "    print the current python version\n",
    "    then print the current date and time\n",
    "    then determine the values in the Fibonacci sequence that that are less than the value of 101?\"\"\"\n",
    "\n",
    "    # print(f\"# User: '{TASK}'\")\n",
    "    success = False\n",
    "    try:\n",
    "        # 6. Invoke the agent for the current thread and print the response\n",
    "        async for response in agent.invoke(messages=TASK, thread=thread):\n",
    "            # print(f\"# Agent: {response}\")\n",
    "            thread = response.thread\n",
    "            success = True\n",
    "    finally:\n",
    "        # 7. Clean up the resources\n",
    "        await thread.delete() if thread else None\n",
    "        await agent.client.beta.assistants.delete(agent.id)\n",
    "        return success\n",
    "        \n",
    "import asyncio\n",
    "\n",
    "async def run_agent_instance(idx) -> bool:\n",
    "    success = await create_agent()\n",
    "    return success\n",
    "\n",
    "async def run_agents_in_parallel():\n",
    "    tasks = [run_agent_instance(i) for i in range(100)]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    print(results)\n",
    "    # results is a list of booleans, count the number of True and False\n",
    "    num_succeeded = results.count(True)\n",
    "    num_failed = results.count(False)\n",
    "    print(f\"Total succeeded: {num_succeeded}\")\n",
    "    print(f\"Total failed: {num_failed}\")\n",
    "\n",
    "# To actually run the agents in parallel, you would call:\n",
    "await run_agents_in_parallel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Kernel + AI Foundry Agent SDK\n",
    "\n",
    "Authentication is also handled with service principals - just need to ensure the SPN has a role assignment to the resource with the `Azure AI User` role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create client with connection string and auth to AI Foundry project\n",
    "client = AzureAIAgent.create_client(endpoint=ai_project_endpoint, credential=EnvironmentCredential())\n",
    "\n",
    "# 2. Create an agent with a code interpreter on the Azure AI agent service\n",
    "code_interpreter = CodeInterpreterTool(file_ids=[])\n",
    "agent_definition = await client.agents.create_agent(\n",
    "    model=model_deployment_name,\n",
    "    tools=code_interpreter.definitions,\n",
    "    tool_resources=code_interpreter.resources,\n",
    "    instructions=\"Run the provided request as code and return the result. ALWAYS USE THE CODE INTERPRETER TOOL.\",\n",
    ")\n",
    "\n",
    "# 3. Create a Semantic Kernel agent for the Azure AI agent\n",
    "agent = AzureAIAgent(\n",
    "    client=client,\n",
    "    definition=agent_definition,\n",
    ")\n",
    "\n",
    "# 4. Create a thread for the agent\n",
    "# If no thread is provided, a new thread will be\n",
    "# created and returned with the initial response\n",
    "thread: AzureAIAgentThread | None = None\n",
    "\n",
    "TASK = \"\"\"Use the python code interpreter, \n",
    "print the current python version\n",
    "then print the current date and time\n",
    "then determine the values in the Fibonacci sequence that that are less than the value of 101?\"\"\"\n",
    "print(f\"# User: '{TASK}'\")\n",
    "\n",
    "try:\n",
    "    # 5. Invoke the agent for the specified thread for response\n",
    "    async for response in agent.invoke(messages=TASK, thread=thread):\n",
    "        print(f\"# Agent: {response}\")\n",
    "        thread = response.thread\n",
    "finally:\n",
    "    # 6. Cleanup: Delete the thread, agent, and file\n",
    "    await thread.delete() if thread else None\n",
    "    await client.agents.delete_agent(agent.id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
